---
title: "쿼리 빌더에서 데이터 스트리밍 처리"
date: "241014"
tags: ["NestJS"]
---

데이터 스트리밍 처리는 대량 데이터를 다룰 때 메모리 사용을 최소화하며, 네트워크나 I/O와 같은 자원을 효율적으로 사용하는 방법입니다.

특히, TypeORM과 같은 ORM 도구로 대량 데이터를 조회할 때 한 번에 메모리에 로드하는 방식은 성능과 안정성에 문제가 발생할 수 있습니다.

이 글에서는 쿼리 빌더를 이용한 스트리밍 개념과 이를 활용하는 방법을 소개합니다.

## 왜 데이터 스트리밍이 중요한가?

#### 메모리 효율성

한 번에 수백만 건의 데이터를 데이터베이스에서 불러오는 것은 메모리와 CPU에 큰 부담을 줍니다.

특히 서버의 메모리가 제한적인 경우, 대량 데이터를 모두 로드하면 Out of Memory 문제가 발생할 수 있습니다.

#### 네트워크 전송 최적화

서버가 데이터를 일괄 처리하는 대신, 작은 청크 단위로 클라이언트에 전달하면 네트워크 병목을 줄일 수 있습니다.

클라이언트는 실시간으로 데이터를 받아 처리할 수 있어 사용자 경험이 향상됩니다.

#### 대규모 서비스에서의 활용

- 실시간 로그 처리: 수백만 건의 로그 데이터를 실시간으로 분석하거나 외부 서비스로 전송
- 대용량 CSV 또는 JSON 내보내기: 모든 데이터를 한 번에 읽지 않고 스트림 방식으로 처리해 파일로 저장
- ETL (Extract, Transform, Load) 작업: 데이터 웨어하우스로 데이터를 옮길 때도 주로 스트리밍 기법 사용

## 쿼리 빌더와 데이터 스트림

TypeORM의 QueryBuilder는 SQL 쿼리를 직접 다루는 동시에 ORM의 편의성을 제공합니다.

스트림은 `QueryBuilder`에서 제공하는 `.stream()` 메서드를 사용해 구현할 수 있습니다.

이 방식은 대량의 쿼리 결과를 메모리에 전부 올리지 않고 순차적으로 처리할 수 있습니다.

## 스트림 쿼리 처리의 내부 동작 원리

#### 일반 쿼리

- `query.getMany()`를 사용하면 모든 데이터를 한 번에 메모리로 로드합니다.
- 데이터가 너무 크면 메모리 부족 에러가 발생할 수 있습니다.
- 예: `SELECT * FROM user` 실행 시 수백만 행이 메모리에 로드됨.

#### 스트림 쿼리

- `.stream()`을 사용하면 쿼리 결과를 데이터베이스 커서(cursor)로 가져옵니다.
- 각 행을 하나씩 가져오며, `data` 이벤트마다 데이터를 처리합니다.
- 대량 데이터를 메모리 절약하며 네트워크로 실시간 전송이 가능합니다.

## PostgreSQL/MySQL에서 데이터 스트림 처리

```ts
import { createQueryBuilder, getConnection } from "typeorm";
import { User } from "./entity/User"; // 사용자 테이블을 위한 엔티티

async function streamUsers() {
  const connection = getConnection();

  const queryStream = connection
    .createQueryBuilder(User, "user")
    .select(["user.id", "user.name", "user.email"])
    .where("user.isActive = :active", { active: true })
    .stream(); // 쿼리 결과를 스트림으로 가져오기

  queryStream.on("data", (row) => {
    console.log(row); // 각 행을 실시간으로 처리
  });

  queryStream.on("end", () => {
    console.log("All rows have been streamed.");
  });

  queryStream.on("error", (err) => {
    console.error("Stream error:", err);
  });
}

streamUsers();
```

- `.stream()`: 쿼리 결과를 Node.js의 `ReadableStream` 형태로 가져옵니다.
- `data` 이벤트: 새로운 데이터가 로드될 때마다 호출됩니다. 대량 데이터에서 메모리 사용을 최적화합니다.
- `end` 이벤트: 모든 데이터가 처리된 후 호출됩니다.

## 스트림을 이용한 파일 저장 (CSV 내보내기)

대량 데이터를 CSV 파일로 내보내야 한다면, 스트림을 통해 데이터를 순차적으로 파일에 기록할 수 있습니다.

```ts
import { createQueryBuilder, getConnection } from "typeorm";
import * as fs from "fs";

async function exportUsersToCSV() {
  const writeStream = fs.createWriteStream("users.csv");
  writeStream.write("id,name,email\n"); // CSV 헤더

  const queryStream = getConnection()
    .createQueryBuilder()
    .select(["id", "name", "email"])
    .from("user", "user")
    .where("isActive = :active", { active: true })
    .stream(); // 데이터베이스 커서를 통해 스트림 가져오기

  queryStream.on("data", (row) => {
    writeStream.write(`${row.id},${row.name},${row.email}\n`); // 데이터 기록
  });

  queryStream.on("end", () => {
    console.log("CSV export completed.");
    writeStream.end();
  });

  queryStream.on("error", (err) => {
    console.error("Stream error:", err);
  });
}

exportUsersToCSV();
```

- fs.createWriteStream(): 파일에 데이터를 스트림 방식으로 기록합니다.
- 데이터베이스와 파일 I/O가 비동기적으로 처리되므로 네트워크 병목 없이 빠르게 처리됩니다.

## 스트림 사용 시 고려할 점

#### 트랜잭션과의 호환성

스트림 쿼리는 트랜잭션과 함께 사용할 때 주의해야 합니다.

커서 기반 쿼리는 트랜잭션 범위에서 사용될 수 있지만, 너무 오래 유지되면 데이터베이스 락 문제가 발생할 수 있습니다.

#### 에러 핸들링

스트림 처리 도중 네트워크 에러나 데이터베이스 에러가 발생할 수 있습니다. `error` 이벤트를 반드시 처리해야 합니다.

#### 메모리 관리

스트림은 기본적으로 메모리를 절약하지만, 만약 처리 속도가 데이터 수신 속도를 따라가지 못하면 메모리 누수가 발생할 수 있습니다.

`pause()`와 `resume()` 메서드를 통해 흐름 제어가 가능합니다.

## 정리하며

쿼리 빌더의 스트림 기능은 대량 데이터를 메모리 효율적으로 처리하고, 실시간 응답성을 개선하는 데 매우 유용합니다.

이 기법은 ETL 파이프라인, 대규모 로그 처리, 실시간 보고서 생성과 같은 다양한 시나리오에서 활용될 수 있습니다.
