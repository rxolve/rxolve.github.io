---
title: "개발자가 꼭 알아둬야 할 유니코드와 문자 집합에 대한 고찰 2"
date: "240918"
tags: ["Article"]
---

> 조엘 온 소프트웨어 4장을 2부로 나누어 정리합니다.

## 인코딩

이제 인코딩이 등장할 시간입니다.

2바이트라는 미신을 이끌어낸 유니코드 인코딩에 대한 초기 아이디어에 따르면 'Hello'는 다음과 같이 표현할 수 있습니다.

00 48 00 65 00 6C 00 6C 00 6F

그렇다면 다음과 같은 표현법은 어떨까요?

48 00 65 00 6C 00 6C 00 6F 00

기술적으로는 두 가지 모두 가능합니다. 이러다보니 하루 아침에 유니코드를 저장하는 방식은 두 가지가 돼버렸습니다.

유니코드 문자열 시작 부분에 FE FF를 저장하는 희한한 관례가 생기고 말았습니다.

이를 유니코드 바이트 순서 표시라고 부르며, 상위와 하위 바이트 순서를 바꿀 경우 FF FE로 보이므로, 이런 문자열을 읽는 경우에 다른 모든 바이트 순서를 반드시 뒤집어야 했습니다.

당연히 프로그래머는 불평을 늘어놓기 시작했죠. 유니코드를 여러 해 동안 무시해왔으며, 그 동안 상황은 더욱 나빠졌습니다.

이때에 맞춰 UTF-8로 부르는 기가 막힌 개념이 등장했습니다.

UTF-8은 유니코드 코드 포인트를 따르는 문자열을 저장하기 위한 또 다른 시스템으로, 8비트 바이트를 사용해서 매직 U+넘버를 기억 공간에 저장합니다.

UTF-8에서는 0에서 127 사이에 존재하는 모든 코드 포인트를 1바이트로 저장합니다. 128 이상의 코드 포인트는 2바이트, 3바이트에서 시작해서 최대 한계인 6바이트까지 확장해서 저장합니다.

| 16진 최소 | 16진 최대 | 이진수로 표현한 바이트 배열                           |
| --------- | --------- | ----------------------------------------------------- |
| 00000000  | 0000007F  | 0xxxxxxx                                              |
| 00000080  | 000007FF  | 110xxxxx 10xxxxxx                                     |
| 00000800  | 0000FFFF  | 1110xxxx 10xxxxxx 10xxxxxx                            |
| 00010000  | 001FFFFF  | 11110xxx 10xxxxxx 10xxxxxx 10xxxxxx                   |
| 00200000  | 03FFFFFF  | 111110xx 10xxxxxx 10xxxxxx 10xxxxxx 10xxxxxx          |
| 04000000  | 7FFFFFFF  | 1111110x 10xxxxxx 10xxxxxx 10xxxxxx 10xxxxxx 10xxxxxx |

이런 방식을 적용할 경우 UTF-8은 ASCII 문자열을 완벽하게 호환하면서, 유니코드 문자열을 효율적으로 저장할 수 있습니다.

아까 살펴본 U+0065 U+006C U+006C U+006F로 표현한 'Hello'는 48 65 6C 6C 6F로 저장할 것이며, 이런 표현 방식은 ASCII, ANSI, 지구상에서 통용되는 모든 OEM 문자 집합으로 저장하는 방식과 동일합니다.

물론 다른 나라 사람들만 온갖 시련을 겪어야 합니다.

> 책에서는 UCS-2, UTF-16, UTF-7, UCS-4, Latin-1(ISO-8859-1)에 대해서도 소개하지만, 이 내용은 생략하겠습니다.

## 인코딩에 대해 가장 중요한 사실 한가지

지금까지 설명한 내용은 모두 까맣게 잊어버린다고 해도, 가장 중요한 사실 하나는 기억합시다.

인코딩 방식을 모르는 문자열은 아무 의미가 없다는 사실입니다.

**'일반텍스트'라는 개념은 존재하지 않습니다.**

메모리나 파일이나 이메일 메시지 내부에 문자열이 있으면 이 문자열 인코딩이 무엇인지 알아야만 하며, 그렇지 못하면 이 문자열을 해석할 수도 없으며 사용자에게 올바르게 보여줄 수도 없습니다.

문자열이 깨지는 어리석은 문제 대부분은 문자열 인코딩 방식이 무엇인지 알려주지 않을 경우, 올바르게 문서를 표기하지 못하거나 심지어 어디서 끝날지 추측할 수조차 없다는 단순한 사실도 모르는 햇병아리 프로그래머들 때문입니다.

문자열 인코딩 방식에 대한 정보를 어떻게 저장할까요?

이메일 메시지라면 헤더에 Content-Type: text/plain; charset="UTF-8"과 같은 문자열 형식을 넣습니다.

웹 페이지인 경우에는 웹서버가 Content-Type과 유사한 http 헤더를 웹 페이지 자체와 함께 반환하는 방식이 초기 아이디어입니다.

하지만 이런 방식에는 중대한 결함이 있습니다. 사이트는 수많은 사람이 온갖 언어로 올린 페이지로 구성돼 있습니다.

이럴 경우 웹서버 자체는 각 파일이 어떤 인코딩을 따르는지 알아챌 방법이 없기에 일괄적으로 시스템 전체에 할당한 Content-Type 헤더를 보낼 수 없습니다.

http 헤더나 메타 태그 어느 쪽에서도 Content-Type을 찾지 못한다면 웹브라우저는 어떻게 해야 할까요?

인터넷 익스플로러는 실제로 무척 흥미로운 작업을 수행합니다.

익스플로러는 특정 언어와 특정 인코딩을 조합했을 때 나타나는 바이트 빈도를 토대로 문서에 사용한 언어와 인코딩 방식을 추측해냅니다.

사람이 사용하는 모든 언어는 글자 사용 빈도 히스토그램에서 특징적인 패턴을 보이기에, 이런 편법이 동작할 가능성은 무척 높습니다.

하지만 이를 엉뚱하게도 인식해서 다른 나라로 표시되는 독자가 무엇을 할 수 있을까요?

보기 - 인코딩 메뉴를 사용해서 수십가지에 이르는 인코딩을 글자를 알아볼 때까지 바꿔볼 수 밖에 없습니다.

물론 이런 방법을 아는 사람도 있지만 모르는 사람이 대부분입니다.

UTF-8은 여러 해에 걸쳐 웹 브라우저가 제대로 지원하는 인코딩입니다.

이런 방식을 통해 조엘 온 소프트웨어를 29개 나라 버전으로 인코딩하게 되며, 아직 조엘 온 소프트웨어 다국어 버전을 읽는 데 문제가 생겼다는 사람을 보지 못했습니다.

## 크롬의 경우

책이 워낙 옛날에 쓰여졌다 보니 크롬의 경우에 어떻게 인코딩 방식을 추측하는지 궁금했습니다.

결과적으로 익스플로러의 추측로직에서 크게 발전하진 못한 것 같습니다.

다음과 같은 절차를 따릅니다.

1. HTTP 헤더와 메타 태그 분석

   우선 크롬은 서버에서 제공하는 HTTP 헤더를 먼저 확인합니다.

   만약 헤더에서 charset 정보가 없으면, 크롬은 HTML 문서의 \<head> 영역에 있는 \<meta charset="..."> 태그를 찾아 문서의 인코딩 방식을 알아냅니다.

2. BOM (Byte Order Mark) 탐지

   만약 HTTP 헤더와 메타 태그 어디에서도 인코딩 정보를 찾지 못한다면, 크롬은 파일의 시작 부분에서 BOM을 확인합니다.

   BOM은 파일의 시작에 추가되는 특수한 바이트 시퀀스로, UTF-8, UTF-16과 같은 특정 인코딩에서 파일의 인코딩을 명시하는 역할을 합니다.

   이를 통해 크롬은 해당 문서가 어떤 인코딩으로 작성되었는지 자동으로 감지할 수 있습니다.

3. 히스토그램 분석 (Fallback)

   만약 HTTP 헤더, 메타 태그, BOM 정보 모두에서 인코딩을 파악하지 못했다면, 크롬은 마지막으로 인코딩을 추론합니다.

   이때 사용하는 방식은 바로 문자 빈도 분석입니다. 익스플로러처럼 크롬도 특정 인코딩에서 나타나는 바이트 패턴을 분석하여 문서의 인코딩을 유추합니다.

   예를 들어, 특정 언어에서는 자주 사용되는 문자들이 고유한 바이트 시퀀스를 가집니다.

   크롬은 이러한 패턴을 바탕으로 어느 정도 정확하게 인코딩을 추론할 수 있습니다.

   이는 전적으로 바이트 히스토그램을 분석하는 방식으로, 특정 언어에서 자주 나타나는 문자들이 해당 언어의 특유한 패턴을 만들어내기 때문에 어느 정도 신뢰할 수 있는 결과를 도출합니다.

> 책을 정리하며 문자열을 표현하기 위한 규격과 인코딩 방식을 개괄할 수 있어 좋았습니다.
>
> 익스플로러와 크롬의 인코딩 추론 방식이 흥미롭습니다.
