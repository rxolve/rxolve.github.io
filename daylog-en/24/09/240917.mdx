---
title: "Understanding Unicode and Character Sets: What Developers Must Know, Part 1"
date: "240917"
tags: ["Article"]
---

> This post is a summary of Chapter 4 from _Joel on Software_, divided into two parts.

If you are a professional developer in the 21st century and do not know about characters, character sets, encoding, or Unicode, we’ll have to arrest you and make you peel onions for six months in a submarine. I swear.

These concepts are not difficult at all.

## A Historical Perspective

In the beautiful days when UNIX was first conceived and K&R wrote _The C Programming Language_, it was sufficient to handle only English characters that didn’t need special symbols.

At that time, there was only a code system called ASCII, which could express every character with a number between 32 and 127.

For example, a space is represented as 32, the letter A as 65, and the lowercase a as 97. It was convenient to store characters using just 7 bits.

However, since most modern computers use an 8-bit byte, a problem arose where too many people had different ideas about how to use the space between 128 and 255.

This chaos ended when the ANSI Standards Committee systematically organized these things into the ANSI standard, with everyone agreeing on how to handle characters below 128.

However, there were still multiple ways to handle characters above 128, depending on the region.

As long as you weren't transferring strings between different computers or handling more than one language on the same machine, there was no issue.

But with the rise of the internet, where transferring strings became routine, the cracks in this system began to show.

## Unicode

Unicode is the result of a brave effort to create a single character set that includes not only all the rational writing systems on Earth but also imaginary languages like Klingon from _Star Trek_.

You might mistakenly think that Unicode is a simple 16-bit character set that can represent only 65,536 characters because each character takes up 16 bits.

This is a misconception, and one of the most common myths, so there’s no need to be embarrassed if you thought this.

In fact, Unicode is more of a philosophy for handling characters, so you need to understand the Unicode way of thinking.

In Unicode, a character is mapped to something called a **code point**, which is purely theoretical.

In Unicode, the letter A is an abstract ideal, floating in space. This abstract A is different from B, and also from the lowercase a. But **A** and _A_ are considered the same.

The Unicode Consortium has assigned a unique number to every conceptual letter in every alphabet, expressed as U+0645.

These unique numbers are called code points. The "U+" refers to Unicode, and the number is expressed in hexadecimal.

You can visit the [Unicode website](https://home.unicode.org) to see the code points assigned to each character.

In practice, there’s no limit to the number of characters Unicode can define.

In fact, since Unicode already exceeds 65,536 code points, not all characters can be compressed into just 2 bytes.

Anyway, the idea of 16-bit Unicode is a myth.

When you represent "Hello" in Unicode, it corresponds to the following five code points:

```plaintext
U+0048 U+0065 U+006C U+006C U+006F
```

These are simply a collection of code points—just numbers, really.

We still haven’t talked about how to express these characters in an email message or load them into memory.

> In the next post, I will cover encoding.

## ASCII vs. ANSI vs. Unicode

### ASCII (American Standard Code for Information Interchange)

- **Release Year**: 1963
- **Bit Size**: 7-bit encoding
- **Number of Characters**: Up to 128 (2^7 = 128)
- **Key Features**:
  - Represents English alphabet letters (uppercase and lowercase), numbers, basic punctuation, and control characters.
  - Widely used and considered the foundation of character encoding.
  - Adopted as the standard by most early computer systems.
  - **Limitations**: Since it uses only 7 bits, it cannot support languages other than English.

### ANSI (American National Standards Institute)

- **Release Year**: 1980s (defined by the American National Standards Institute)
- **Bit Size**: Typically 8-bit encoding (up to 256 characters, 2^8 = 256)
- **Number of Characters**: Extends ASCII to include more characters.
- **Key Features**:
  - Includes additional characters beyond 128, allowing it to represent special characters and accents in European languages like French and German.
  - The interpretation of ANSI varies by operating system or region, and the character sets supported differ.
  - **Limitations**: Regional variations in character encoding made it difficult to maintain consistency, a problem later addressed by Unicode.

### Unicode

- **Release Year**: 1991
- **Bit Size**: 16 bits and beyond
- **Number of Characters**: Over 143,000 characters (now exceeds 16 bits to include even more characters)
- **Key Features**:
  - Can represent all written languages in the world.
  - Supports complex characters such as Korean, Chinese, and Japanese, as well as emojis.
  - **Code Points**: Each character in Unicode is assigned a unique code point, such as U+0041 for the letter 'A'.
  - **Encoding Formats**: Unicode characters are stored and transmitted using formats like UTF-8, UTF-16, and UTF-32. UTF-8 is the most widely used and allows for efficient storage with variable length.

### Key Differences Summary

| Item                     | **ASCII**               | **ANSI**                          | **Unicode**                                                     |
| ------------------------ | ----------------------- | --------------------------------- | --------------------------------------------------------------- |
| **Release Year**         | 1963                    | 1980s                             | 1991                                                            |
| **Bit Size**             | 7-bit                   | 8-bit                             | 16-bit or more                                                  |
| **Number of Characters** | 128                     | 256                               | Over 143,000                                                    |
| **Supported Languages**  | English                 | English + European                | All languages worldwide + Emoji                                 |
| **Encoding Type**        | Fixed-length            | Fixed-length                      | UTF-8, UTF-16, UTF-32 (supports both variable and fixed-length) |
| **Scalability**          | Very limited            | Some European language extensions | Infinite scalability                                            |
| **Representation**       | English-based documents | Varies by region                  | All languages, characters, symbols, and special symbols         |
